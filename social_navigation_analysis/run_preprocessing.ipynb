{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "........./Users/matty_gee/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis/preprocess.py:1359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.array(np.nancumsum(values, axis=0) /\n",
      "/Users/matty_gee/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis/preprocess.py:1359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.array(np.nancumsum(values, axis=0) /\n",
      "/Users/matty_gee/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis/preprocess.py:1359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.array(np.nancumsum(values, axis=0) /\n",
      "/Users/matty_gee/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis/preprocess.py:1359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.array(np.nancumsum(values, axis=0) /\n",
      "/Users/matty_gee/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis/preprocess.py:1359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.array(np.nancumsum(values, axis=0) /\n",
      "/Users/matty_gee/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis/preprocess.py:1359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.array(np.nancumsum(values, axis=0) /\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.089s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets: ['CUD' 'HC' 'PD' 'PTSD' 'prolific_initial_vt' 'prolific_initial'\n",
      " 'prolific_replication' 'schema_day01' 'schema_day03' 'adolescent_pilot'\n",
      " 'schema_day01_older' 'schema_day03_older']\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob, datetime, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pycircstat\n",
    "warnings.filterwarnings('ignore') # ignore all!\n",
    "\n",
    "# directory to social_navigation_analysis\n",
    "user = os.path.expanduser('~')\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, str(Path(f'{user}/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis'))) \n",
    "import preprocess as snt_preprc\n",
    "from preprocess import load_data\n",
    "from info import decision_trials\n",
    "import utils\n",
    "\n",
    "# samples:\n",
    "main_dir = f'{user}/Desktop/SNT_data'\n",
    "datasets = pd.read_excel(f'{main_dir}/SNT-datasets.xlsx') \n",
    "print(f\"All datasets: {datasets['sample'].values}\")\n",
    "\n",
    "# test main function\n",
    "%run -i '../tests/test_ComputeBehavior2.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>raw_directory</th>\n",
       "      <th>raw_format</th>\n",
       "      <th>experimenter</th>\n",
       "      <th>options_version</th>\n",
       "      <th>last_processed</th>\n",
       "      <th>n_raw_files</th>\n",
       "      <th>n_organized_files</th>\n",
       "      <th>n_timing_files</th>\n",
       "      <th>n_behavior_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUD</td>\n",
       "      <td>SNT-fmri_CUD/Data/SNT/Logs</td>\n",
       "      <td>log</td>\n",
       "      <td>kb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-11 18:24:42.497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HC</td>\n",
       "      <td>SNT-fmri_original/Data/SNT/Logs</td>\n",
       "      <td>log</td>\n",
       "      <td>rt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-11 18:26:04.754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PD</td>\n",
       "      <td>SNT-behavior_PD/Data/SNT/Logs</td>\n",
       "      <td>log</td>\n",
       "      <td>nr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-11 18:26:27.132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PTSD</td>\n",
       "      <td>SNT-behavior_PTSD/Data/SNT/Logs</td>\n",
       "      <td>log</td>\n",
       "      <td>af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-11 18:27:24.168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prolific_initial_vt</td>\n",
       "      <td>SNT-online_behavioral/Data/Initial_2021/SNT/Ra...</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>standard</td>\n",
       "      <td>2022-11-16 14:28:11.782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prolific_initial</td>\n",
       "      <td>SNT-online_behavioral/Data/Initial_2021/SNT/Ra...</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>standard</td>\n",
       "      <td>2022-11-11 17:32:46.319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prolific_replication</td>\n",
       "      <td>SNT-online_behavioral/Data/Replication_2022/SN...</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>standard</td>\n",
       "      <td>2022-11-11 17:33:22.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>schema_day01</td>\n",
       "      <td>SNT-online_schema/Data/SNT/day01/Raw</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>schema</td>\n",
       "      <td>2022-11-11 17:45:58.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>schema_day03</td>\n",
       "      <td>SNT-online_schema/Data/SNT/day03/Raw</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>schema</td>\n",
       "      <td>2022-11-11 17:46:14.593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adolescent_pilot</td>\n",
       "      <td>SNT-online_adolescent_pilot/Data/SNT/CSVs</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>adolescent_pilot</td>\n",
       "      <td>2022-11-11 18:16:55.603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>schema_day01_older</td>\n",
       "      <td>SNT-online_schema/Data/SNT/Older/Day01/Raw</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>schema</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>schema_day03_older</td>\n",
       "      <td>SNT-online_schema/Data/SNT/Older/Day03/Raw</td>\n",
       "      <td>csv</td>\n",
       "      <td>ms</td>\n",
       "      <td>schema</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sample                                      raw_directory  \\\n",
       "0                    CUD                         SNT-fmri_CUD/Data/SNT/Logs   \n",
       "1                     HC                    SNT-fmri_original/Data/SNT/Logs   \n",
       "2                     PD                      SNT-behavior_PD/Data/SNT/Logs   \n",
       "3                   PTSD                    SNT-behavior_PTSD/Data/SNT/Logs   \n",
       "4    prolific_initial_vt  SNT-online_behavioral/Data/Initial_2021/SNT/Ra...   \n",
       "5       prolific_initial  SNT-online_behavioral/Data/Initial_2021/SNT/Ra...   \n",
       "6   prolific_replication  SNT-online_behavioral/Data/Replication_2022/SN...   \n",
       "7           schema_day01               SNT-online_schema/Data/SNT/day01/Raw   \n",
       "8           schema_day03               SNT-online_schema/Data/SNT/day03/Raw   \n",
       "9       adolescent_pilot          SNT-online_adolescent_pilot/Data/SNT/CSVs   \n",
       "10    schema_day01_older         SNT-online_schema/Data/SNT/Older/Day01/Raw   \n",
       "11    schema_day03_older         SNT-online_schema/Data/SNT/Older/Day03/Raw   \n",
       "\n",
       "   raw_format experimenter   options_version          last_processed  \\\n",
       "0         log           kb               NaN 2022-11-11 18:24:42.497   \n",
       "1         log           rt               NaN 2022-11-11 18:26:04.754   \n",
       "2         log           nr               NaN 2022-11-11 18:26:27.132   \n",
       "3         log           af               NaN 2022-11-11 18:27:24.168   \n",
       "4         csv           ms          standard 2022-11-16 14:28:11.782   \n",
       "5         csv           ms          standard 2022-11-11 17:32:46.319   \n",
       "6         csv           ms          standard 2022-11-11 17:33:22.139   \n",
       "7         csv           ms            schema 2022-11-11 17:45:58.004   \n",
       "8         csv           ms            schema 2022-11-11 17:46:14.593   \n",
       "9         csv           ms  adolescent_pilot 2022-11-11 18:16:55.603   \n",
       "10        csv           ms            schema                     NaT   \n",
       "11        csv           ms            schema                     NaT   \n",
       "\n",
       "    n_raw_files  n_organized_files  n_timing_files  n_behavior_files  \n",
       "0           NaN                NaN             NaN               NaN  \n",
       "1           NaN                NaN             NaN               NaN  \n",
       "2           NaN                NaN             NaN               NaN  \n",
       "3           NaN                NaN             NaN               NaN  \n",
       "4           NaN                NaN             NaN               NaN  \n",
       "5           NaN                NaN             NaN               NaN  \n",
       "6           NaN                NaN             NaN               NaN  \n",
       "7           NaN                NaN             NaN               NaN  \n",
       "8           NaN                NaN             NaN               NaN  \n",
       "9           NaN                NaN             NaN               NaN  \n",
       "10          NaN                NaN             NaN               NaN  \n",
       "11          NaN                NaN             NaN               NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dir = f'{user}/Desktop/SNT_data'\n",
    "datasets = pd.read_excel(f'{main_dir}/SNT-datasets.xlsx') \n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTING BEHAVIOR\n",
      "PD: found 61 files\n",
      "Summarizing behavior computing behavior\n",
      "Found 0 errors of 61\n"
     ]
    }
   ],
   "source": [
    "# Usage notes:\n",
    "# expects & creates some folder structure like:\n",
    "    # SNT/Raw_files\n",
    "    # SNT/Organized\n",
    "    # SNT/Behavior\n",
    "    # SNT/Posttask\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# convenience functions\n",
    "\n",
    "def find_files(directory):\n",
    "    return [f for f in glob.glob(f\"{directory}/*\") if '~$' not in f]\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# dataset info\n",
    "# synapse_dir = '/Volumes/synapse/projects/SocialSpace/Projects/'\n",
    "# datasets    = pd.read_excel(f'{synapse_dir}/SNT-datasets.xlsx') \n",
    "\n",
    "main_dir = f'{user}/Desktop/SNT_data'\n",
    "datasets = pd.read_excel(f'{main_dir}/SNT-datasets.xlsx') \n",
    "samples  = ['PD'] # datasets['sample'].values # \n",
    "\n",
    "# print(f\"All datasets: {datasets['sample'].values}\")\n",
    "# print(f'Selected datasets: {samples}')\n",
    "\n",
    "# what to do\n",
    "overwrite      = True\n",
    "parse_data     = False\n",
    "compute_beh    = True \n",
    "summarize_beh  = True\n",
    "summarize_post = False\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    #---------------------------\n",
    "    # define the project details\n",
    "    #---------------------------\n",
    "\n",
    "    \n",
    "    proj_ix     = np.where(datasets['sample'].values==sample)[0][0]\n",
    "    project_dir = f\"{datasets.loc[proj_ix,'raw_directory']}\"\n",
    "    file_format = datasets.loc[proj_ix,'raw_format']\n",
    "    datasets.loc[proj_ix, 'last_processed'] = datetime.datetime.now()\n",
    "    raw_dir    = f\"{main_dir}/{datasets.loc[proj_ix, 'raw_directory']}\"\n",
    "\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    if parse_data: \n",
    "        # parse the raw file into an organized file\n",
    "    #------------------------------------------------\n",
    "\n",
    "    \n",
    "        # find files\n",
    "        raw_files = find_files(raw_dir)\n",
    "        raw_files.sort()\n",
    "        print(f'{sample}: found {len(raw_files)} files')\n",
    "        errors = []\n",
    "        for raw_fname in raw_files:\n",
    "\n",
    "            fname = raw_fname.split('/')[-1]\n",
    "        \n",
    "            try:\n",
    "\n",
    "                print(f'{fname}: parsing raw', end='\\r')\n",
    "\n",
    "                if file_format == 'log':\n",
    "                    xlsx_fname = snt_preprc.parse_log(raw_fname, experimenter=datasets.loc[proj_ix,'experimenter'], \n",
    "                                                      output_timing=True, out_dir=f'{raw_dir}/..')\n",
    "                \n",
    "                elif file_format == 'csv':\n",
    "                    xlsx_fname = snt_preprc.parse_csv(raw_fname, snt_version=datasets.loc[proj_ix,'options_version'], \n",
    "                                                      out_dir=f'{raw_dir}/..')\n",
    "                \n",
    "                elif file_format == 'txt': # txt -> csv -> xlsx\n",
    "                    csv_raw_dir = raw_dir.replace('-txt', '-csv')\n",
    "                    raw_fname   = snt_preprc.format_txt_as_csv(raw_fname, out_dir=csv_raw_dir)\n",
    "                    xlsx_fname  = snt_preprc.parse_csv(raw_fname, snt_version=datasets.loc[proj_ix,'options_version'], \n",
    "                                                       out_dir=f'{csv_raw_dir}/..')\n",
    "\n",
    "            except: \n",
    "\n",
    "                errors.append(f'Parsing raw: {raw_fname}')\n",
    "        \n",
    "        \n",
    "    #------------------------------------------------\n",
    "    if compute_beh: \n",
    "        print('COMPUTING BEHAVIOR')\n",
    "        # compute behavior from organized file \n",
    "    #------------------------------------------------\n",
    "\n",
    "    \n",
    "        if sample != 'schema_day03': # doesnt have snt \n",
    "\n",
    "            xlsx_files = find_files(f'{raw_dir}/../Organized') # where organized directory should have been made\n",
    "            xlsx_files.sort()\n",
    "            print(f'{sample}: found {len(xlsx_files)} files')\n",
    "            errors = []\n",
    "\n",
    "            for xi, xlsx_fname in enumerate(xlsx_files):\n",
    "\n",
    "                try: \n",
    "\n",
    "                    fname = xlsx_fname.split('/')[-1]\n",
    "                    if (overwrite) or (not os.path.isfile(f'{raw_dir}/../Behavior/{fname}_behavior.xlsx')): \n",
    "                        print(f'{xi+1}/{len(xlsx_files)} {fname}: computing behavior', end='\\r')       \n",
    "                        snt_preprc.compute_behavior(xlsx_fname, \n",
    "                                                    weight_types=False, \n",
    "                                                    decision_types=False, \n",
    "                                                    coord_types=False, \n",
    "                                                    overwrite=overwrite,\n",
    "                                                    out_dir=f'{raw_dir}/..')\n",
    "\n",
    "                except: \n",
    "\n",
    "                    errors.append(f'Computing behavior: {xlsx_fname}')\n",
    "\n",
    "        #------------------------------------------\n",
    "        # compute rdvs for mvpa analyses\n",
    "        #------------------------------------------\n",
    "        #  print(f'Finished parsing & computing behavior with {len(errors)} errors')\n",
    "        # # check number of files:\n",
    "        #  n_xlsx = find_files(f\"{raw_dir}/../Organized\")\n",
    "        #  if len(raw_files) != n_xlsx: print('There are missing organized excel files')\n",
    "\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    if summarize_beh: \n",
    "        # summarize across subjects\n",
    "    #------------------------------------------------\n",
    "\n",
    "    \n",
    "        if 'schema_day03' not in sample: # doesnt have snt\n",
    "\n",
    "            #------------------------------------------------\n",
    "            print('Summarizing behavior')\n",
    "            #------------------------------------------------\n",
    "\n",
    "            # n_timing    = len([f for f in glob.glob(f\"{project_dir}/{datasets.loc[proj_ix, 'timing_directory']}/*\") if '~$' not in f])\n",
    "            # datasets.loc[proj_ix, 'n_raw_files']       = n_raw\n",
    "            # datasets.loc[proj_ix, 'n_organized_files'] = n_xlsx\n",
    "            # datasets.loc[proj_ix, 'n_timing_files']    = n_timing\n",
    "            # datasets.loc[proj_ix, 'n_behavior_files']  = n_behavior\n",
    "\n",
    "            # check number of files:\n",
    "            xlsx_files  = find_files(f\"{raw_dir}/../Organized\")\n",
    "            behav_files = find_files(f\"{raw_dir}/../Behavior\")\n",
    "            if len(xlsx_files) != len(behav_files): print(f'There are missing behavioral files: {len(behav_files)}!={len(xlsx_files)}')\n",
    "            snt_preprc.summarize_behavior(behav_files, out_dir=f'{raw_dir}/..')\n",
    "\n",
    "    #------------------------------------------------\n",
    "    if summarize_post: \n",
    "        # summarize across subjects\n",
    "    #------------------------------------------------\n",
    "    \n",
    "        # if there is a posttask folder concatenate autoamatically and output:\n",
    "        if os.path.exists(f'{raw_dir}/../Posttask'):\n",
    "            \n",
    "            #------------------------------------------------\n",
    "            print('Summarizing posttask')\n",
    "            #------------------------------------------------\n",
    "\n",
    "            post_files = find_files(f'{raw_dir}/../Posttask')\n",
    "            post_df = pd.concat([pd.read_excel(f) for f in post_files], axis=0)\n",
    "            post_df.rename(columns={'Unnamed: 0':'sub_id'}, inplace=True)\n",
    "            post_df.to_excel(f'{raw_dir}/../SNT-posttask_n{len(post_df)}.xlsx', index=False)\n",
    "\n",
    "            # TODO: add in dots, self-reports, posttask etc automatically... eg, check if there is another summary sheet available, add in as an argument to merge on sub_id column?\n",
    "# datasets.to_excel(f'{main_dir}/SNT-datasets.xlsx', index=False)\n",
    "\n",
    "print(f'Found {len(errors)} errors')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "summary_dir = '/Users/matty_gee/Desktop/SNT_data/SNT-fmri_original/Data/SNT'\n",
    "dfs = []\n",
    "for fname in ['SNT-behavior_n*', 'Self*']:\n",
    "    df = pd.read_excel(glob.glob(f'{summary_dir}/{fname}')[0])\n",
    "    df.sort_values(by='sub_id', inplace=True)\n",
    "    df['sub_id'] = df['sub_id'].astype(int)\n",
    "    dfs.append(df)\n",
    "summary_df = functools.reduce(lambda x, y: pd.merge(x, y, on = 'sub_id', how = 'outer'), dfs)\n",
    "first_cols = ['sub_id']\n",
    "summary_df.insert(1, 'dx', 'HC')\n",
    "summary_df.to_excel(f'{summary_dir}/All-data_summary_n{len(summary_df)}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = '/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Summary'\n",
    "cud_df = pd.read_excel(f'{summary_dir}/All-data_summary_n84.xlsx')\n",
    "pd.concat([cud_df, summary_df]).to_excel('All-data_summary_n{len(cud_df)+len(summary_df)}.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir  = '/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT'\n",
    "# beh_dir   = f'{base_dir}/Behavior'\n",
    "# beh_files = glob.glob(beh_dir + '/*.xlsx')\n",
    "\n",
    "# if compute_rdvs:\n",
    "# snt_preprc.compute_rdvs(beh_file, metric='euclidean', output_all=False, out_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory + dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory processing completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#-----------------------\n",
    "# version details\n",
    "#-----------------------\n",
    "\n",
    "synapse_dir = '/Volumes/synapse/projects/SocialSpace/Projects/'\n",
    "task_versions = pd.read_excel(f'{synapse_dir}/SNT-datasets_task-versions.xlsx', sheet_name='CUD')\n",
    "task_versions.sort_values(by='character_role_num', inplace=True)\n",
    "\n",
    "sample   = 'CUD'\n",
    "data_dir = '/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data'\n",
    "info     = pd.read_excel(f'{data_dir}/Summary/SNT-task_versions_n84.xlsx')\n",
    "\n",
    "#-----------------------\n",
    "# memory\n",
    "#-----------------------\n",
    "\n",
    "roles = ['first', 'second', 'assistant', 'powerful', 'boss', 'neutral']\n",
    "ans = ['powerful','powerful','boss','neutral','first','assistant','first','second','neutral','powerful',\n",
    "       'boss','first','neutral','assistant','assistant','neutral','second','powerful','assistant','second',\n",
    "       'neutral','second','powerful','first','boss','first','boss','assistant','second','boss'] # this will probably be the same for the ptsd sample too?\n",
    "\n",
    "mem_df = pd.read_excel(glob.glob(f'{data_dir}/Summary/SNT-memory*_raw.xlsx')[0])\n",
    "n_mem  = len(mem_df)\n",
    "if not os.path.exists(f'{data_dir}/Summary/SNT-memory_n{n_mem}.xlsx'):\n",
    "\n",
    "    memory_df = []\n",
    "    for s,sub in mem_df.iterrows():\n",
    "\n",
    "        # get correct version\n",
    "        task_ver = task_versions[[c for c in task_versions.columns if f'v{sub.Task_ver}' in c]]\n",
    "        opts     = [x.lower() for x in task_ver[f'v{sub.Task_ver}_name']]\n",
    "\n",
    "        # score the answers\n",
    "        resps   = np.array([x.lower() for x in list(sub.values[2:])]) \n",
    "        resps   = [roles[opts.index(r)] for r in resps] # get characte role for each response\n",
    "        correct = (np.array(resps) == np.array(ans)) * 1\n",
    "\n",
    "        df = pd.DataFrame([sub.Sub_id, sub.Task_ver] + list(correct)).T\n",
    "        df.columns = ['sub_id', 'task_version'] + [f'memory_{q+1}_{a}' for q, a in enumerate(ans)]\n",
    "        memory_df.append(df)\n",
    "    memory_df = pd.concat(memory_df)\n",
    "\n",
    "    # add means\n",
    "    for role in roles:\n",
    "        memory_df[f'memory_{role}'] = np.mean(memory_df[[c for c in memory_df.columns if role in c]], axis=1)\n",
    "    memory_df['memory_mean'] = np.mean(memory_df[[c for c in memory_df.columns if 'memory' in c]], axis=1)\n",
    "    memory_df['memory_mean_main'] = np.mean(memory_df[[f'memory_{r}' for r in roles[:5]]], axis=1)\n",
    "    memory_df.to_excel(f'{data_dir}/Summary/SNT-memory_n{len(memory_df)}_processed.xlsx', index=False)\n",
    "\n",
    "print('Memory processing completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------\n",
    "# dots\n",
    "#-----------------------\n",
    "\n",
    "dots_dir  = f'{data_dir}/SNT/Dots'\n",
    "dots_jpgs = glob.glob(f'{dots_dir}/Dots*jpg')\n",
    "print(f'Found {len(dots_jpgs)} dots jpgs')\n",
    "recon_dir = f'{dots_dir}/recon'\n",
    "if not os.path.exists(recon_dir): os.mkdir(recon_dir)\n",
    "\n",
    "# append to an existing dots summary if it exists\n",
    "initial_fname = glob.glob(f'{data_dir}/Summary/SNT-dots_n*.xlsx')\n",
    "if initial_fname: \n",
    "    dots_df  = pd.read_excel(initial_fname[0])\n",
    "    dots_df.sort_values(by='sub_id', inplace=True)\n",
    "    dots_df.reset_index(drop=True, inplace=True)\n",
    "    sub_list = dots_df['sub_id'].values\n",
    "    dots_df = [dots_df]\n",
    "else:\n",
    "    sub_list = []\n",
    "    dots_df = []\n",
    "\n",
    "print(f'{len(sub_list)} subjects dots already processed')\n",
    "\n",
    "for j, jpg in enumerate(dots_jpgs):\n",
    "\n",
    "    sub_id = int(jpg.split('Dots_')[1].split('.jpg')[0])\n",
    "    if sub_id in sub_list:\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(f'{j+1} {jpg}', end=\"\\r\")\n",
    "            recon_img, df = snt_preprc.process_dots(jpg)\n",
    "            recon_img.save(f'{recon_dir}/Dots-recon_{sub_id}.jpg')\n",
    "\n",
    "            # get the correct character roles for each dot\n",
    "            sub_ix   = np.where(info['sub_id'].values == sub_id)[0][0]\n",
    "            task_v   = info.loc[sub_ix, 'snt_ver'] \n",
    "            task_ver = task_versions[[c for c in task_versions.columns if f'v{task_v}' in c]]\n",
    "            chars    = {name: roles[i] for i, name in enumerate(task_ver[f'v{task_v}_dots-name'])}\n",
    "            df.columns = [col.replace(x, chars[x]) for x in chars for col in df.columns if x in col]         \n",
    "            df.insert(0, 'sub_id', sub_id)\n",
    "            dots_df.append(df)\n",
    "\n",
    "        except:\n",
    "\n",
    "            print(f'ERROR: {jpg}')\n",
    "\n",
    "# dots_df = pd.concat(dots_df)\n",
    "# dots_df.to_excel(f'{data_dir}/Summary/SNT-dots_n{len(dots_df)}.xlsx', index=False)\n",
    "if initial_fname: os.remove(initial_fname) # replace old w/ new\n",
    "print('Dots processing completed')\n",
    "\n",
    "\n",
    "#-----------------------\n",
    "# merge all\n",
    "#-----------------------\n",
    "\n",
    "# summary_files = [f for f in glob.glob(f'{data_dir}/Summary/*') if ('~$' not in f) and ('All-summary') not in f]\n",
    "# merged_df     = utils.merge_dfs(summary_files)\n",
    "# merged_df     = utils.move_cols_to_front(merged_df, ['sub_id', 'dx'])\n",
    "# merged_df.to_excel(f'{data_dir}/Summary/All-summary_n{len(merged_df)}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_navigation_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3f7fb9d13e0b7cd346c5bcfe5de21908f17a2d0dcbd7821a2fa8e4fbf9948e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
